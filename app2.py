import streamlit as st
import pandas as pd
import os

# è¨­å®šç¶²é é…ç½®
st.set_page_config(page_title="2025 è—¥åƒ¹è¯åˆæŸ¥è©¢ç³»çµ±", layout="wide")

# --- å½ˆå‡ºèªªæ˜è¦–çª—å…§å®¹ ---
@st.dialog("ç³»çµ±ä½¿ç”¨èªªæ˜èˆ‡ç°¡ä»‹")
def show_help():
    st.markdown("""
    ### ğŸŒŸ ç³»çµ±ç°¡ä»‹
    æœ¬ç³»çµ±æ•´åˆæ—¥æœ¬åšç”Ÿå‹å‹•çœ (MHLW) **2025 å¹´ 4 æœˆ**æœ€æ–°ç™¼å¸ƒçš„è—¥åƒ¹åŸºæº–è³‡æ–™ï¼Œçµåˆ **KEGG é†«å­¸è³‡æ–™åº«** èˆ‡ **Azure AI ç¿»è­¯** æŠ€è¡“ï¼Œæä¾›è·¨é¡åˆ¥çš„è—¥åƒ¹æª¢ç´¢æœå‹™ã€‚

    ### ğŸš€ æ ¸å¿ƒç”¨é€”
    1. **è—¥åƒ¹ç¯„åœæª¢ç´¢**ï¼šè‡ªå‹•èšåˆã€ŒåŒæˆåˆ†ã€åŒè¦æ ¼ã€è—¥å“ï¼Œé¡¯ç¤ºå¸‚å ´æœ€ä½èˆ‡æœ€é«˜è—¥åƒ¹ã€‚
    2. **è·¨åŠ‘å‹å°æ¯”**ï¼šä¸€æ¬¡æœå°‹å³å¯æŸ¥çœ‹è©²æˆåˆ†åœ¨ã€Œå…§æœã€å¤–ç”¨ã€æ³¨å°„ã€é½’ç§‘ã€é¡åˆ¥çš„åƒ¹æ ¼åˆ†å¸ƒã€‚
    3. **å°ˆæ¥­é†«å­¸ç¿»è­¯**ï¼šæä¾›ç²¾ç¢ºçš„æ—¥ã€è‹±æˆåˆ†å°ç…§ã€‚

    ### ğŸ“– ä½¿ç”¨èªªæ˜
    * **æœå°‹æ–¹å¼**ï¼šåœ¨æœå°‹æ¡†è¼¸å…¥æ—¥æ–‡ï¼ˆå¦‚ï¼š`ã‚¢ã‚¹ãƒ”ãƒªãƒ³`ï¼‰æˆ–è‹±æ–‡ï¼ˆå¦‚ï¼š`Aspirin`ï¼‰ã€‚
    * **è—¥åƒ¹é¡¯ç¤º**ï¼šè‹¥è¦æ ¼å­˜åœ¨å¤šå€‹å» ç‰Œï¼Œé¡¯ç¤ºç‚º `Â¥æœ€ä½ ï½ Â¥æœ€é«˜`ã€‚
    * **ä¾†æºæ¨™è¨»**ï¼šæ¨™è¨»è©²è³‡è¨Šä¾†è‡ªé½’ç§‘ã€å…§ç”¨ã€å¤–ç”¨æˆ–æ³¨å°„é¡åˆ¥ã€‚
    * **è©³ç´°è³‡æ–™**ï¼šé»æ“Šã€ŒæŸ¥çœ‹åŸå§‹è©³æƒ…ã€å¯çœ‹åˆ°ç”Ÿç”¢å» å•†èˆ‡å®Œæ•´å“åã€‚
    
    ---
    *è³‡æ–™ä¾†æºï¼š[æ—¥æœ¬åšç”Ÿå‹å‹•çœ ä»¤å’Œ7å¹´4æœˆè—¥åƒ¹åŸºæº–](https://www.mhlw.go.jp/topics/2025/04/tp20250401-01.html)*
    """)

# --- è³‡æ–™è¼‰å…¥é‚è¼¯ (ä¿æŒä¸è®Š) ---
@st.cache_data
def load_and_combine_data():
    file_map = {
        "é½’ç§‘": "medical_translation_final (é½’ç§‘).xlsx",
        "å¤–ç”¨": "medical_translation_final (å¤–ç”¨).xlsx",
        "å…§ç”¨": "medical_translation_final (å…§ç”¨).xlsx",
        "æ³¨å°„": "medical_translation_final(æ³¨å°„).xlsx"
    }
    combined_list = []
    for source_label, file_name in file_map.items():
        if os.path.exists(file_name):
            try:
                df = pd.read_excel(file_name)
                cols = ['æˆåˆ†å', 'è‹±æ–‡æˆåˆ†å', 'è¦æ ¼', 'è–¬ä¾¡']
                df = df[cols].copy()
                df['ä¾†æºé¡å‹'] = source_label
                df['è–¬ä¾¡'] = pd.to_numeric(df['è–¬ä¾¡'], errors='coerce')
                combined_list.append(df)
            except Exception: pass
    return pd.concat(combined_list, ignore_index=True) if combined_list else pd.DataFrame()

db = load_and_combine_data()

# --- ä¸»ä»‹é¢ ---
col_title, col_help = st.columns([8, 2])

with col_title:
    st.title("ğŸ” 2025 å¹´åº¦è—¥åƒ¹è¯åˆæŸ¥è©¢ç³»çµ±")

with col_help:
    st.write("") # èª¿æ•´å°é½Š
    if st.button("â“ ä½¿ç”¨èªªæ˜"):
        show_help()

st.caption("å„ªå…ˆé¡¯ç¤ºåŒæˆåˆ†ã€åŒè¦æ ¼ä¹‹è—¥åƒ¹å€é–“ (æœ€ä½~æœ€é«˜)")

# --- æœå°‹é‚è¼¯ ---
search_input = st.text_input("è«‹è¼¸å…¥æˆåˆ†åç¨±ï¼ˆæ—¥æ–‡æˆ–è‹±æ–‡ï¼‰ï¼š", placeholder="ä¾‹å¦‚ï¼šLidocaine æˆ– ãƒªãƒ‰ã‚«ã‚¤ãƒ³").strip().lower()

if search_input:
    mask = (db['æˆåˆ†å'].str.contains(search_input, case=False, na=False) | 
            db['è‹±æ–‡æˆåˆ†å'].str.contains(search_input, case=False, na=False))
    res = db[mask]

    if not res.empty:
        summary = res.groupby(['æˆåˆ†å', 'è‹±æ–‡æˆåˆ†å', 'è¦æ ¼']).agg({
            'è–¬ä¾¡': ['min', 'max'],
            'ä¾†æºé¡å‹': lambda x: 'ã€'.join(sorted(x.unique()))
        }).reset_index()
        summary.columns = ['æˆåˆ†å', 'è‹±æ–‡æˆåˆ†å', 'è¦æ ¼', 'Min', 'Max', 'è³‡æ–™ä¾†æº']
        
        summary['è—¥åƒ¹ (JPY)'] = summary.apply(
            lambda r: f"Â¥{r['Min']:,.2f}" if r['Min'] == r['Max'] else f"Â¥{r['Min']:,.2f} ï½ Â¥{r['Max']:,.2f}", axis=1
        )
        
        st.table(summary[['æˆåˆ†å', 'è‹±æ–‡æˆåˆ†å', 'è¦æ ¼', 'è—¥åƒ¹ (JPY)', 'è³‡æ–™ä¾†æº']])
        
        with st.expander("æŸ¥çœ‹åŸå§‹å“é …è©³æƒ…"):
            st.dataframe(res)
    else:
        st.warning("æŸ¥ç„¡ç¬¦åˆæˆåˆ†ã€‚")
