import streamlit as st
import pandas as pd
import os

st.set_page_config(page_title="å¤šä¾†æºè—¥åƒ¹æŸ¥è©¢ç³»çµ±", layout="wide")

@st.cache_data
def load_combined_data():
    """è¼‰å…¥ä¸¦æ•´åˆç›®éŒ„ä¸‹çš„å››å€‹ XLSX æª”æ¡ˆ"""
    # å®šç¾©æª”æ¡ˆåç¨±èˆ‡å°æ‡‰çš„æ¨™ç±¤
    file_config = {
        "é½’ç§‘": "medical_translation_final (é½’ç§‘).xlsx",
        "å¤–ç”¨": "medical_translation_final (å¤–ç”¨).xlsx",
        "å…§ç”¨": "medical_translation_final (å…§ç”¨).xlsx",
        "æ³¨å°„": "medical_translation_final(æ³¨å°„).xlsx"
    }
    
    combined_list = []
    
    for source_label, file_name in file_config.items():
        if os.path.exists(file_name):
            try:
                # è®€å– Excel æª”æ¡ˆ
                df = pd.read_excel(file_name)
                
                # ç¯©é¸å¿…è¦æ¬„ä½ï¼Œé¿å…æ¬„ä½åç¨±å¾®å·®å°è‡´éŒ¯èª¤
                # å‡è¨­æ¬„ä½åç¨±ç‚ºï¼šæˆåˆ†å, è‹±æ–‡æˆåˆ†å, è¦æ ¼, è–¬ä¾¡
                df = df[['æˆåˆ†å', 'è‹±æ–‡æˆåˆ†å', 'è¦æ ¼', 'è–¬ä¾¡']].copy()
                
                # æ–°å¢è³‡æ–™ä¾†æºæ¨™ç±¤
                df['ä¾†æº'] = source_label
                
                # æ¸…æ´—è—¥åƒ¹æ•¸æ“šï¼šç¢ºä¿ç‚ºæ•¸å€¼ï¼Œè™•ç†å¯èƒ½çš„ç©ºå€¼
                df['è–¬ä¾¡'] = pd.to_numeric(df['è–¬ä¾¡'], errors='coerce')
                
                combined_list.append(df)
            except Exception as e:
                st.error(f"è®€å– {file_name} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        else:
            st.warning(f"æé†’ï¼šæœªåœ¨ç›®éŒ„ä¸‹æ‰¾åˆ°æª”æ¡ˆ {file_name}")
            
    if not combined_list:
        return pd.DataFrame()
        
    return pd.concat(combined_list, ignore_index=True)

# è¼‰å…¥è³‡æ–™åº«
df_db = load_combined_data()

st.title("ğŸ” è¯åˆè—¥åƒ¹æŸ¥è©¢ç³»çµ±")
st.markdown("è¼¸å…¥ **æ—¥æ–‡æˆåˆ†å** æˆ– **è‹±æ–‡æˆåˆ†å**ï¼Œç³»çµ±å°‡è‡ªå‹•æ¯”å° **é½’ç§‘ã€å¤–ç”¨ã€å…§ç”¨ã€æ³¨å°„** å››å¤§ä¾†æºä¹‹åƒ¹æ ¼ã€‚")

# æœå°‹åˆ—
query = st.text_input("è¼¸å…¥æœå°‹é—œéµå­—ï¼ˆä¾‹å¦‚ï¼šãƒªãƒ‰ã‚«ã‚¤ãƒ³ æˆ– Lidocaineï¼‰", "").strip().lower()

if query:
    # æ¨¡ç³Šæœå°‹æ—¥æ–‡èˆ‡è‹±æ–‡æ¬„ä½
    mask = (
        df_db['æˆåˆ†å'].str.contains(query, case=False, na=False) | 
        df_db['è‹±æ–‡æˆåˆ†å'].str.contains(query, case=False, na=False)
    )
    search_results = df_db[mask]

    if not search_results.empty:
        # ä¾ç…§ã€Œæˆåˆ†åã€èˆ‡ã€Œè¦æ ¼ã€åˆ†çµ„ï¼Œçµ±è¨ˆè—¥åƒ¹èˆ‡ä¾†æº
        # åŒè¦æ ¼ä¸åŒåƒ¹è€…ï¼Œçµ±è¨ˆå…¶ Min èˆ‡ Max
        summary = search_results.groupby(['æˆåˆ†å', 'è‹±æ–‡æˆåˆ†å', 'è¦æ ¼']).agg({
            'è–¬ä¾¡': ['min', 'max'],
            'ä¾†æº': lambda x: ', '.join(sorted(x.unique()))
        }).reset_index()

        # é‡æ–°å‘½åæ¬„ä½
        summary.columns = ['æˆåˆ†å', 'è‹±æ–‡æˆåˆ†å', 'è¦æ ¼', 'æœ€ä½è—¥åƒ¹', 'æœ€é«˜è—¥åƒ¹', 'ä¾†æºæ¨™ç¤º']

        # è™•ç†è—¥åƒ¹é¡¯ç¤ºé‚è¼¯
        def format_price_range(row):
            p_min = row['æœ€ä½è—¥åƒ¹']
            p_max = row['æœ€é«˜è—¥åƒ¹']
            if pd.isna(p_min): return "ç„¡è³‡æ–™"
            if p_min == p_max:
                return f"{p_min:,.1f}"
            else:
                return f"{p_min:,.1f} ï½ {p_max:,.1f}"

        summary['è—¥åƒ¹ (JPY)'] = summary.apply(format_price_range, axis=1)

        # é¡¯ç¤ºæœ€çµ‚å ±è¡¨
        st.subheader(f"æ‰¾åˆ° {len(summary)} é …ç¬¦åˆè¦æ ¼çš„çµæœ")
        st.table(summary[['æˆåˆ†å', 'è‹±æ–‡æˆåˆ†å', 'è¦æ ¼', 'è—¥åƒ¹ (JPY)', 'ä¾†æºæ¨™ç¤º']])
        
        # é¡¯ç¤ºè©³ç´°åŸå§‹æ¸…å–®ï¼ˆåŒ…å«å“åèˆ‡å» å•†ï¼‰
        with st.expander("æŸ¥çœ‹åŸå§‹è©³ç´°è³‡æ–™ï¼ˆå«æ‰€æœ‰æ”¶éŒ„å“é …ï¼‰"):
            st.dataframe(search_results.sort_values(by='è–¬ä¾¡'))
    else:
        st.error("æŸ¥ç„¡è³‡æ–™ï¼Œè«‹å˜—è©¦å…¶ä»–é—œéµå­—ã€‚")

else:
    st.info("è«‹è¼¸å…¥æˆåˆ†åç¨±é€²è¡ŒæŸ¥è©¢ã€‚")

# çµ±è¨ˆå´é‚Šæ¬„
if not df_db.empty:
    st.sidebar.header("è³‡æ–™åº«çµ±è¨ˆ")
    st.sidebar.write(f"ç¸½å“é …æ•¸ï¼š{len(df_db)}")
    for src in ["é½’ç§‘", "å¤–ç”¨", "å…§ç”¨", "æ³¨å°„"]:
        count = len(df_db[df_db['ä¾†æº'] == src])
        st.sidebar.text(f"Â· {src}: {count} ç­†")
